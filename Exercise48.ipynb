{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = raw_input('> ')\n",
    "\n",
    "words = stuff.split()\n",
    "\n",
    "\n",
    "\n",
    "first_word = ('direction', 'north') \n",
    "\n",
    "second_word = ('verb', 'go') \n",
    "\n",
    "sentence = [first_word, second_word]\n",
    "\n",
    "\n",
    "\n",
    "def convert_number(s):\n",
    "\n",
    "    try:\n",
    "\n",
    "\t\treturn int(s)\n",
    "\n",
    "\texcept ValueError:\n",
    "\n",
    "\t\treturn None\n",
    "\n",
    "\t\t\n",
    "\n",
    "from nose.tools \n",
    "\n",
    "import * from ex48 import lexicon\n",
    "\n",
    "\n",
    "\n",
    "def test_directions():\n",
    "\n",
    "    assert_equal(lexicon.scan(\"north\"), [('direction', 'north')])\n",
    "\n",
    "    result = lexicon.scan(\"north south east\")\n",
    "\n",
    "    assert_equal(result, [('direction', 'north'),\n",
    "\n",
    "\t\t\t\t\t\t('direction', 'south'),\n",
    "\n",
    "\t\t\t\t\t\t('direction', 'east')]) \n",
    "\n",
    "\n",
    "\n",
    "def test_verbs():\n",
    "\n",
    "\tassert_equal(lexicon.scan(\"go\"), [('verb', 'go')])\n",
    "\n",
    "    result = lexicon.scan(\"go kill eat\")\n",
    "\n",
    "    assert_equal(result, [('verb', 'go'),\n",
    "\n",
    "\t\t\t\t\t\t ('verb', 'kill'),\n",
    "\n",
    "\t\t\t\t\t\t ('verb', 'eat')])\n",
    "\n",
    "\t\t\t\t\t\t \n",
    "\n",
    "\t\t\t\t\t\t \n",
    "\n",
    "def test_stops():\n",
    "\n",
    "    assert_equal(lexicon.scan(\"the\"), [('stop', 'the')])\n",
    "\n",
    "    result = lexicon.scan(\"the in of\")\n",
    "\n",
    "\tassert_equal(result, [('stop', 'the'),\n",
    "\n",
    "\t\t\t\t\t\t ('stop', 'in'),\n",
    "\n",
    "\t\t\t\t\t\t ('stop', 'of')])\n",
    "\n",
    "\t\t\t\t\t\t \n",
    "\n",
    "\t\t\t\t\t\t \n",
    "\n",
    "def test_nouns():\n",
    "\n",
    "    assert_equal(lexicon.scan(\"bear\"), [('noun', 'bear')])\n",
    "\n",
    "    result = lexicon.scan(\"bear princess\")\n",
    "\n",
    "    assert_equal(result, [('noun', 'bear'),\n",
    "\n",
    "\t\t\t\t\t\t ('noun', 'princess')])\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "def test_numbers():\n",
    "\n",
    "\tassert_equal(lexicon.scan(\"1234\"), [('number', 1234)])\n",
    "\n",
    "    result = lexicon.scan(\"3 91234\")\n",
    "\n",
    "    assert_equal(result, [('number', 3),\n",
    "\n",
    "\t\t\t\t\t\t ('number', 91234)])\n",
    "\n",
    "\t\t\t\t\t\t \n",
    "\n",
    "def test_errors():\n",
    "\n",
    "    assert_equal(lexicon.scan(\"ASDFADFASDF\"), [('error', 'ASDFADFASDF')])\n",
    "\n",
    "    result = lexicon.scan(\"bear IAS princess\")\n",
    "\n",
    "    assert_equal(result, [('noun', 'bear'),\n",
    "\n",
    "\t\t\t\t\t\t ('error', 'IAS'),\n",
    "\n",
    "\t\t\t\t\t\t ('noun', 'princess')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
